# Самостоятельная работа по теме количество информации

## Вариант 1

1. Сообщение $A$ несёт на $\log_2 3$ бит информации больше, чем сообщение $B$. Найдите отношение вероятностей появления этих событий.

2. Игральный кубик подбросили 5 раз. Для каждого броска записали 0, если результат кратен трём и 1 - в противном случае. Получили сообщение из пяти нулей и единиц. Найдите энтропию этого сообщения.

3. В тексте встречаются символы: `Й` - 200 раз, `Ц` - 100 раз, `У` - 300 раз, `К` - 400 раз, точка - 50 раз, пробел - 200 раз. Других символов нет.
     - Найдите общее количество информации по Шеннону в этом тексте;
     - Найдите энтропию одного символа;
     - (*) Предложите оптимальное бинарное префиксное кодирование для символов в тексте и найдите объём всего текста в битах при таком кодировании.

## Вариант 2

1. Сообщение $X$ несёт на $\log_2 5$ бит информации меньше, чем сообщение $Y$. Найдите отношение вероятностей появления этих событий.

2. Игральный кубик подбросили 8 раз. Для каждого броска записали 0, если результат меньше 3 и 1 - в противном случае. Получили сообщение из восьми нулей и единиц. Найдите энтропию этого сообщения.

3. В тексте встречаются символы: `Ф` - 100 раз, `Ы` - 300 раз, `В` - 200 раз, `А` - 400 раз, точка - 200 раз, пробел - 50 раз. Других символов нет.
     - Найдите общее количество информации по Шеннону в этом тексте;
     - Найдите энтропию одного символа;
     - (*) Предложите оптимальное бинарное префиксное кодирование для символов в тексте и найдите объём всего текста в битах при таком кодировании.
