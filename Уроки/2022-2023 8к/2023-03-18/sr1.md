# Самостоятельная работа по теме количество информации

## Вариант 1

1. Вероятность появления сообщения $A$ в три раза больше вероятности появления сообщения $B$. Какое сообщение несёт больше информации и на сколько?

2. В классе 30 учеников, из которых две пары однофамильцев. Учитель равновероятно выбирает одного из учеников и сообщает вам его фамилию. Найдите энтропию этого эксперимента.

3. В тексте встречаются символы: `А` - 1000 раз, `В` - 2000 раз, `У` - 1500 раз, `Ъ` - 100 раз, точка - 400 раз, пробел - 800 раз. Других символов нет.
     - Найдите общее количество информации по Шеннону в этом тексте;
     - Найдите энтропию одного символа;
     - (*) Предложите оптимальное бинарное префиксное кодирование для символов в тексте и найдите объём всего текста в битах при таком кодировании.

## Вариант 2

1. Вероятность появления сообщения $X$ в пять раз меньше вероятности появления сообщения $Y$. Какое сообщение несёт больше информации и на сколько?

2. В классе 12 учеников, из которых одна пара однофамильцев. Учитель равновероятно выбирает одного из учеников и сообщает вам его фамилию. Найдите энтропию этого эксперимента.

3. В тексте встречаются символы: `Х` - 1500 раз, `Ш` - 2000 раз, `Э` - 1000 раз, `Ц` - 100 раз, точка - 800 раз, пробел - 400 раз. Других символов нет.
     - Найдите общее количество информации по Шеннону в этом тексте;
     - Найдите энтропию одного символа;
     - (*) Предложите оптимальное бинарное префиксное кодирование для символов в тексте и найдите объём всего текста в битах при таком кодировании.
